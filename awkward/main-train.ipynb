{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 설치\n",
    "#!git clone https://github.com/kh-kim/simple-ntc.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!\n",
    "\n",
    "#!pip install --user --upgrade pip\n",
    "#!pip install --user pytorch-ignite\n",
    "#!pip install --user fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.기존 모델\n",
    "!python train.py --model_fn ./model.pth --train /home/work/data/awkward_v2/data/albert_pretrain/sen_sen_label_v1_test.csv --cnn --gpu_id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-1. rnn\n",
    "!python train.py --model_fn ./model.pth --train /home/work/data/awkward_v2/data/albert_pretrain/sen_sen_label_v1_test.csv --rnn --gpu_id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3. 새로 추가된 모델\n",
    "!python train.py --model_fn ./model.pth --train /home/work/data/awkward_v2/data/albert_pretrain/sen_sen_label_v1_test.csv --awkward --gpu_id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3-1. 새로 추가된 모델\n",
    "!python train.py --model_fn ./model.pth --train /home/work/data/awkward_v2/data/albert_pretrain/sen_sen_label_v1_test_v2.csv --awkward --gpu_id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-1. 새로 추가된 모델\n",
    "!python train.py --model_fn ./model.pth --train /home/work/data/awkward_v2/data/albert_pretrain/sen_sen_label_v1_test_v2.csv --awkward --gpu_id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nohup python train.py --model_fn ./model_gpu_1g_v1.pth --train /home/work/data/awkward_v2/data/albert_pretrain/xaa --awkward --gpu_id 0 & > awkward_train_0626_1g_v1.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python train.py --model_fn ./model_gpu_1g_1layer_v3.pth --train /home/work/data/awkward_v2/data/albert_pretrain/xaa.tsv --awkward --gpu_id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델불러오기 & 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classify import *\n",
    "from engine.models.awkward import awkwardClassifier\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "import torch\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./\"\n",
    "model_name = \"model_gpu_nsp_cosine_v7.pth\"\n",
    "use_eos=False\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data = torch.load(path + model_name, map_location = 'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "config = saved_data['config']\n",
    "awkward_best = saved_data['awkward']\n",
    "vocab1 = saved_data['vocab1']\n",
    "vocab2 = saved_data['vocab2']\n",
    "classes = saved_data['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab1_size = len(vocab1)\n",
    "vocab2_size = len(vocab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_field():\n",
    "    '''\n",
    "    To avoid use DataLoader class, just declare dummy fields. \n",
    "    With those fields, we can retore mapping table between words and indice.\n",
    "    '''\n",
    "    return (\n",
    "        data.Field(sequential = True,\n",
    "                              use_vocab = True,\n",
    "                              batch_first = True,\n",
    "                              include_lengths = False,\n",
    "                              eos_token='<EOS>' if use_eos else None,\n",
    "                              pad_first=True\n",
    "                              ),\n",
    "        data.Field(sequential = True,\n",
    "                              use_vocab = True,\n",
    "                              batch_first = True,\n",
    "                              include_lengths = False,\n",
    "                              eos_token='<EOS>' if use_eos else None,\n",
    "                              pad_first=True\n",
    "                              ),        \n",
    "        data.Field(sequential = False,\n",
    "                             preprocessing = lambda x: int(x),\n",
    "                                 use_vocab = True,\n",
    "                                init_token = None,\n",
    "                                 unk_token = None\n",
    "                              )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_field, text2_field, label_field = define_field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_field.vocab = vocab1\n",
    "text2_field.vocab = vocab2 \n",
    "label_field.vocab = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "line1 = \"코로나 극혐\"\n",
    "line2 = \"다양한 기획들이 퍼즐처럼 맞추어 지듯이 객관적으로 필요한 절차에 도움이 될 자료들을 준비할 것입니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines1 = []\n",
    "lines2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines1 += [line1.strip().split(' ')]\n",
    "lines2 += [line2.strip().split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x1 = text1_field.numericalize(\n",
    "    text1_field.pad(lines1),\n",
    "    device='cuda:0' if torch.cuda.is_available() else 'cpu',\n",
    "    )\n",
    "    \n",
    "    x2 = text2_field.numericalize(\n",
    "    text2_field.pad(lines2),\n",
    "    device='cuda:0' if torch.cuda.is_available() else 'cpu',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = awkwardClassifier(\n",
    "    ntoken = vocab1_size,\n",
    "    ntoken2 = vocab2_size,\n",
    "    ninp = config.word_vec_size,\n",
    "    n_classes=n_classes,\n",
    "    nhead = config.nhead, \n",
    "    nhid = config.nhid, \n",
    "    nlayers = config.nlayers,\n",
    "    cos = config.cos,\n",
    "    dropout=config.dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = []\n",
    "model.load_state_dict(awkward_best)\n",
    "ensemble += [model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if config.gpu_id >= 0:\n",
    "    model.cuda(config.gpu_id)\n",
    "    \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_maxseq_to_batch(batch, max_length, device=-1):\n",
    "    \n",
    "    if batch.size(1) >= max_length:\n",
    "        batch = batch[:, :max_length]\n",
    "        \n",
    "    else:\n",
    "        pad_num = max_length - batch.size(1)\n",
    "        pad = torch.ones(batch.size(0), pad_num, device=device) # pad 값이 vocab index 1이라는 가정.\n",
    "        batch = torch.cat([pad.long(), batch], dim=-1)\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = pad_to_maxseq_to_batch(x1, config.max_length, device='cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "x2 = pad_to_maxseq_to_batch(x2, config.max_length, device='cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model(x1, x2)[0])\n",
    "result = torch.argmax(model(x1, x2)[0], dim=-1)\n",
    "#model(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1이면 정상\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시행착오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classify import *\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine.models.awkward import awkwardClassifier\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "use_eos=False\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model.pth'\n",
    "path = \"/home/work/data/awkward_v2/my_model/datajuny_model_v2/datajuny_model_v2/\"\n",
    "\n",
    "saved_data = torch.load(path + model_name,\n",
    "                       map_location = 'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_config = saved_data['config']\n",
    "rnn_best = saved_data['rnn']\n",
    "cnn_best = saved_data['cnn']\n",
    "awkward_best = saved_data['awkward']\n",
    "vocab1 = saved_data['vocab1']\n",
    "vocab2 = saved_data['vocab2']\n",
    "classes = saved_data['classes']\n",
    "\n",
    "vocab1_size = len(vocab1)\n",
    "vocab2_size = len(vocab2)\n",
    "\n",
    "def define_field():\n",
    "    '''\n",
    "    To avoid use DataLoader class, just declare dummy fields. \n",
    "    With those fields, we can retore mapping table between words and indice.\n",
    "    '''\n",
    "    return (\n",
    "        data.Field(sequential = True,\n",
    "                              tokenize=okt.morphs,\n",
    "                              use_vocab = True,\n",
    "                              batch_first = True,\n",
    "                              include_lengths = False,\n",
    "                              eos_token='<EOS>' if use_eos else None,\n",
    "                              pad_first=True\n",
    "                              ),\n",
    "        data.Field(sequential = True,\n",
    "                              tokenize=okt.morphs,\n",
    "                              use_vocab = True,\n",
    "                              batch_first = True,\n",
    "                              include_lengths = False,\n",
    "                              eos_token='<EOS>' if use_eos else None,\n",
    "                              pad_first=True\n",
    "                              ),        \n",
    "        data.Field(sequential = False,\n",
    "                             preprocessing = lambda x: int(x),\n",
    "                                 use_vocab = True,\n",
    "                                init_token = None,\n",
    "                                 unk_token = None\n",
    "                              )\n",
    "    )\n",
    "\n",
    "\n",
    "def read_text():\n",
    "    '''\n",
    "    Read text from standard input for inference.\n",
    "    '''\n",
    "    lines = []\n",
    "\n",
    "    for line in sys.stdin:\n",
    "        if line.strip() != '':\n",
    "            lines += [line.strip().split(' ')]\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "text1_field, text2_field, label_field = define_field()\n",
    "\n",
    "text1_field.vocab = vocab1 # 학습된 vocab을 넣는다.\n",
    "text2_field.vocab = vocab2 \n",
    "label_field.vocab = classes\n",
    "\n",
    "lines = read_text()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # convert string to list of index\n",
    "    x = text1_field.numericalize(\n",
    "        lines,   # 패딩 함수 제외\n",
    "        device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    \n",
    "    ensemble = []\n",
    "    \n",
    "    if awkward_best is not None:\n",
    "\n",
    "        model = awkwardClassifier(\n",
    "                ntoken = vocab1_size,\n",
    "                ntoken2 = vocab2_size,\n",
    "                ninp = train_config.word_vec_size,\n",
    "                n_classes=n_classes,\n",
    "                nhead = train_config.nhead, \n",
    "                nhid = train_config.nhid, \n",
    "                nlayers = train_config.nlayers,\n",
    "                dropout = train_config.dropout,\n",
    "            )\n",
    "        \n",
    "        model.load_state_dict(awkward_best)\n",
    "        ensemble += [model]\n",
    "\n",
    "    \n",
    "#device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awkward_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  이하 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(9,64,3)\n",
    "b = torch.randn(9,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_outs = torch.exp(-torch.reduce_sum(torch.abs(gen_x - gen_x2), axis=1, keepdims=True))\n",
    "#torch.abs(a - b)\n",
    "\n",
    "torch.exp(-torch.sum(torch.abs(a - b), dim=2, keepdim=True), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([0, 1, 0, 0, 1, 1, 1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape(9, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0], [1], [0], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test =  torch.tensor([\n",
    "        [[-2.1972, -2.1972],\n",
    "         [-2.1972, -2.1972],\n",
    "         [-2.1722, -2.4636],\n",
    "         [-2.2590, -2.0194],\n",
    "         [-2.2590, -2.0194],\n",
    "         [-2.1484, -1.9949]],\n",
    "    \n",
    "        [[-2.1972, -2.1972],\n",
    "         [-2.1972, -2.1972],\n",
    "         [-2.1722, -2.4636],\n",
    "         [-2.2590, -2.0194],\n",
    "         [-2.2590, -2.0194],\n",
    "         [-2.1484, -1.9949]],\n",
    "    \n",
    "        [[-2.1972, -2.1972],\n",
    "         [-2.1972, -2.1972],\n",
    "         [-2.4241, -1.1426],\n",
    "         [-2.2590, -2.0194],\n",
    "         [-2.2590, -2.0194],\n",
    "         [2.1484, -1.9949]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(test, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[-1.0981e+00, -4.0572e-01, -1.9729e+01],\n",
    "        [-1.3451e+00, -3.0182e-01, -1.9530e+01],\n",
    "        [-2.6087e+00, -7.6487e-02, -1.2722e+01],\n",
    "        [-3.8712e-01, -1.1364e+00, -1.1096e+01],\n",
    "        [-2.5002e+00, -8.5733e-02, -9.2695e+00],\n",
    "        [-1.0667e+00, -4.2310e-01, -7.0658e+00],\n",
    "        [-2.2130e+00, -1.1596e-01, -9.0048e+00],\n",
    "        [-1.2529e+00, -3.3737e-01, -7.2923e+00],\n",
    "        [-5.9003e+00, -5.1762e+00, -8.4233e-03]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.tensor([[[-1.4528, -1.1640, -0.7900],\n",
    "         [-1.0151, -1.0604, -1.2334],\n",
    "         [-1.0151, -1.0604, -1.2334],\n",
    "         [-1.0151, -1.0604, -1.2334],\n",
    "         [-1.0151, -1.0604, -1.2334],\n",
    "         [-1.0373, -1.1923, -1.0728]],\n",
    "\n",
    "        [[-1.0151, -1.0604, -1.2334],\n",
    "         [-1.9611, -1.0075, -0.7049],\n",
    "         [-1.0151, -1.0604, -1.2334],\n",
    "         [-0.5327, -1.7920, -1.4011],\n",
    "         [-0.5327, -1.7920, -1.4011],\n",
    "         [-0.5327, -1.7920, -1.4011]],\n",
    "\n",
    "        [[-1.0151, -1.0604, -1.2334],\n",
    "         [-1.9611, -1.0075, -0.7049],\n",
    "         [-1.0151, -1.0604, -1.2334],\n",
    "         [-0.5327, -1.7920, -1.4011],\n",
    "         [-0.5327, -1.7920, -1.4011],\n",
    "         [-0.5327, -1.7920, -1.4011]],\n",
    "\n",
    "        [[-1.0151, -1.0604, -1.2334],\n",
    "         [-1.0151, -1.0604, -1.2334],\n",
    "         [-1.0151, -1.0604, -1.2334],\n",
    "         [-0.5327, -1.7920, -1.4011],\n",
    "         [-0.5327, -1.7920, -1.4011],\n",
    "         [-0.5327, -1.7920, -1.4011]],\n",
    "\n",
    "        [[-1.0151, -1.0604, -1.2334],\n",
    "         [-1.0151, -1.0604, -1.2334],\n",
    "         [-1.0151, -1.0604, -1.2334],\n",
    "         [-0.5327, -1.7920, -1.4011],\n",
    "         [-0.5327, -1.7920, -1.4011],\n",
    "         [-0.5327, -1.7920, -1.4011]],\n",
    "\n",
    "        [[-1.0151, -1.0604, -1.2334],\n",
    "         [-1.0151, -1.0604, -1.2334],\n",
    "         [-0.5327, -1.7920, -1.4011],\n",
    "         [-0.5327, -1.7920, -1.4011],\n",
    "         [-0.5327, -1.7920, -1.4011],\n",
    "         [-0.5327, -1.7920, -1.4011]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.squeeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.gather(1, 2).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.reshape(36,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[-1.4330, -0.8303, -1.1224],\n",
    "         [-1.4330, -0.8303, -1.1224],\n",
    "         [-1.4330, -0.8303, -1.1224],\n",
    "         [-1.4330, -0.8303, -1.1224],\n",
    "         [-1.4330, -0.8303, -1.1224],\n",
    "         [-1.7831, -0.3082, -2.3317]],\n",
    "        [[-1.4330, -0.8303, -1.1224],\n",
    "         [-1.4330, -0.8303, -1.1224],\n",
    "         [-1.4330, -0.8303, -1.1224],\n",
    "         [-1.4330, -0.8303, -1.1224],\n",
    "         [-1.4330, -0.8303, -1.1224],\n",
    "         [-1.7831, -0.3082, -2.3317]],\n",
    "        [[-1.4330, -0.8303, -1.1224],\n",
    "         [-1.5234, -0.9641, -0.9146],\n",
    "         [-1.4330, -0.8303, -1.1224],\n",
    "         [-1.3189, -2.1232, -0.4895],\n",
    "         [-1.3189, -2.1232, -0.4895],\n",
    "         [-1.3189, -2.1232, -0.4895]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = torch.tensor([[[-1.1486, -1.0664, -1.0828],\n",
    "         [-1.1486, -1.0664, -1.0828],\n",
    "         [-1.1486, -1.0664, -1.0828],\n",
    "         [-1.2105, -2.0290, -0.5613],\n",
    "         [-1.2105, -2.0290, -0.5613],\n",
    "         [-1.2105, -2.0290, -0.5613]],\n",
    "\n",
    "        [[-1.1486, -1.0664, -1.0828],\n",
    "         [-1.1486, -1.0664, -1.0828],\n",
    "         [-1.2105, -2.0290, -0.5613],\n",
    "         [-1.2105, -2.0290, -0.5613],\n",
    "         [-1.2105, -2.0290, -0.5613],\n",
    "         [-1.2105, -2.0290, -0.5613]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(te, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = torch.tensor([[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.5 on Python 3.6 (CUDA 10.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
